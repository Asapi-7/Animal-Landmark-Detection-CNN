import os
import torch
import numpy as np
import time
from PIL import Image
from torch.utils.data import Dataset
from torchvision.transforms import functional as F
from torchvision import transforms as T
from torch.utils.data import DataLoader
import glob # ğŸ‘ˆ è¿½åŠ : ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆå–å¾—ç”¨
from sklearn.model_selection import train_test_split # ğŸ‘ˆ è¿½åŠ : ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ç”¨

# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ç”¨
from resnet50_backbone import resnet50 
from torchvision.models.detection.backbone_utils import _resnet_fpn_extractor
from torchvision.ops.feature_pyramid_network import LastLevelP6P7 # ğŸ‘ˆ ä»¥å‰ã®ModuleNotFoundErrorã®ä¿®æ­£
from torchvision.models.detection import RetinaNet

import torch.optim as optim

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
class CustomObjectDetectionDataset(Dataset):
    # âš ï¸ __init__ã‚’ä¿®æ­£: rootã§ã¯ãªãã€ç”»åƒãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚‹
    def __init__(self, img_list, root, transforms=None):
        self.root = root # .ptsãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«rootã‚’ä¿æŒ
        self.transforms = transforms
        self.imgs = img_list # ğŸ‘ˆ æ—¢ã«åˆ†å‰²ã•ã‚ŒãŸç”»åƒãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨
        
    def _parse_pts(self, pts_path):
        """
        .ptsãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã¨ãƒ©ãƒ™ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹é–¢æ•°
        """
        boxes = []
        labels = []

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        if not os.path.exists(pts_path):
             # .ptsãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™ï¼ˆç‰©ä½“ãªã—ï¼‰
             return np.array([], dtype=np.float32).reshape(0, 4), np.array([], dtype=np.int64)
        
        with open(pts_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if not parts:
                    continue
                # å½¢å¼: class_id x_min y_min x_max y_max
                class_id = int(parts[0])
                # åº§æ¨™ã¯æ•´æ•°ã«å¤‰æ›
                coords = [int(p) for p in parts[1:5]]
                
                boxes.append(coords)
                labels.append(class_id)
        
        # NumPyé…åˆ—ã«å¤‰æ›
        boxes = np.array(boxes, dtype=np.float32)
        labels = np.array(labels, dtype=np.int64)
        
        return boxes, labels
        
    def __getitem__(self, idx):
        # 1. ç”»åƒã¨PTSãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        # self.imgs ã«ã¯ 'dataset/img001.jpg' ã®ã‚ˆã†ãªç›¸å¯¾ãƒ‘ã‚¹ãŒå…¥ã£ã¦ã„ã‚‹ã“ã¨ã‚’æƒ³å®š
        img_path_full = self.imgs[idx]
        
        # rootã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡ºï¼ˆimg_listãŒçµ¶å¯¾ãƒ‘ã‚¹ã®å ´åˆã€ã“ã“ã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«åã ã‘æŠ½å‡ºã™ã‚‹ï¼‰
        img_filename = os.path.basename(img_path_full)
        base_name = os.path.splitext(img_filename)[0]
        pts_filename = base_name + ".pts"
        
        # .ptsãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ä½œæˆ
        pts_path = os.path.join(self.root, pts_filename)

        # 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        img = Image.open(img_path_full).convert("RGB") # ğŸ‘ˆ ä¿®æ­£: img_path_fullã‚’ä½¿ç”¨
        boxes_np, labels_np = self._parse_pts(pts_path)

        # 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¾æ›¸ã®ä½œæˆï¼ˆRetinaNetã®è¦æ±‚å½¢å¼ï¼‰
        if boxes_np.size == 0:
            boxes = torch.zeros((0, 4), dtype=torch.float32)
            labels = torch.zeros((0,), dtype=torch.int64)
        else:
            boxes = torch.as_tensor(boxes_np, dtype=torch.float32)
            labels = torch.as_tensor(labels_np, dtype=torch.int64)
        
        target = {}
        target["boxes"] = boxes
        target["labels"] = labels
        target["image_id"] = torch.tensor([idx])
        
        # 4. å¤‰æ›ï¼ˆtransformsï¼‰ã®é©ç”¨
        if self.transforms is not None:
            img, target = self.transforms(img, target)

        return img, target

    def __len__(self):
        return len(self.imgs)

# Transformsã®å®šç¾©
def get_transform(train):
    t = [T.ToTensor()] 
    if train:
        # t.append(T.RandomHorizontalFlip(0.5))
        pass 
    return T.Compose(t)


# Collate Functionã®å®šç¾©
def custom_collate_fn(batch):
    images = [item[0] for item in batch]
    targets = [item[1] for item in batch]
    return images, targets

# =========================================================
# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åˆ†å‰² (ã“ã®éƒ¨åˆ†ãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å‰²ã®æ ¸å¿ƒã§ã™)
# =========================================================

# ãƒ‡ãƒ¼ã‚¿ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®šï¼ˆç”»åƒã¨.ptsãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´æ‰€ï¼‰
DATA_ROOT = '/workspace/dataset'

# 1. å…¨ã¦ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
# os.path.join(DATA_ROOT, "*.jpg") ã¯ã€ä¾‹: /workspace/dataset/*.jpg ã«ãªã‚Šã¾ã™
all_imgs = sorted(glob.glob(os.path.join(DATA_ROOT, "*.jpg")))

print(f"ç™ºè¦‹ã—ãŸå…¨ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(all_imgs)}")

# 2. å­¦ç¿’ç”¨ (80%) ã¨ãƒ†ã‚¹ãƒˆç”¨ (20%) ã«åˆ†å‰²
# test_size=0.2 ã§ 20% ã‚’ãƒ†ã‚¹ãƒˆç”¨ã«å‰²ã‚Šå½“ã¦ã‚‹
train_imgs, test_imgs = train_test_split(
    all_imgs, 
    test_size=0.2, 
    random_state=42 # ã‚·ãƒ¼ãƒ‰å›ºå®šã§å†ç¾æ€§ã‚’ç¢ºä¿
)

print(f"å­¦ç¿’ç”¨ã‚µãƒ³ãƒ—ãƒ«æ•° (80%): {len(train_imgs)}, ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«æ•° (20%): {len(test_imgs)}")


# 3. Datasetã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆï¼ˆåˆ†å‰²ã—ãŸãƒªã‚¹ãƒˆã‚’æ¸¡ã™ï¼‰
train_dataset = CustomObjectDetectionDataset(train_imgs, DATA_ROOT, get_transform(train=True))
test_dataset = CustomObjectDetectionDataset(test_imgs, DATA_ROOT, get_transform(train=False))


# 4. DataLoaderã®ä½œæˆ
train_loader = DataLoader(
    train_dataset,
    batch_size=4, 
    shuffle=True,
    num_workers=2, 
    collate_fn=custom_collate_fn 
)

# âš ï¸ ãƒ†ã‚¹ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‚‚ä½œæˆ
test_loader = DataLoader(
    test_dataset,
    batch_size=4, 
    shuffle=False, # è©•ä¾¡æ™‚ã¯ã‚·ãƒ£ãƒƒãƒ•ãƒ«ä¸è¦
    num_workers=2, 
    collate_fn=custom_collate_fn 
)

# =========================================================
# ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨å­¦ç¿’ãƒ«ãƒ¼ãƒ— (å¤‰æ›´ãªã—)
# =========================================================

# ResNet50ã‚’ä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
custom_backbone = resnet50(pretrained=False) 

# FPNã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®è¨­å®š
out_channels = 256

backbone_fpn = _resnet_fpn_extractor(
    custom_backbone, 
    trainable_layers=5, 
    extra_blocks=LastLevelP6P7(out_channels, out_channels)
)

# RetinaNetãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
NUM_CLASSES = 10 

model = RetinaNet(
    backbone=backbone_fpn,
    num_classes=NUM_CLASSES,
    weights=None 
)

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®å®šç¾©
optimizer = optim.SGD(
    model.parameters(), 
    lr=0.005,
    momentum=0.9,
    weight_decay=0.0001
)

# å­¦ç¿’ã™ã‚‹ã‚¨ãƒãƒƒã‚¯æ•°
num_epochs = 10 

print(f"å­¦ç¿’ã‚’ {device} ã§é–‹å§‹ã—ã¾ã™...")

model.train() # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š

for epoch in range(num_epochs):
    start_time = time.time()
    total_epoch_loss = 0
    
    for step, (images, targets) in enumerate(train_loader):
        # 1. ãƒ‡ãƒ¼ã‚¿ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’GPUã«ç§»å‹•
        images = list(image.to(device) for image in images)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        # 2. å‹¾é…ã‚’ã‚¼ãƒ­ã‚¯ãƒªã‚¢
        optimizer.zero_grad()

        # 3. ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹: æå¤±ã‚’è¨ˆç®—
        loss_dict = model(images, targets) 
        
        # æå¤±ã®åˆè¨ˆ
        losses = sum(loss for loss in loss_dict.values())
        total_epoch_loss += losses.item()

        # 4. ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹: å‹¾é…ã‚’è¨ˆç®—
        losses.backward()

        # 5. ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®ã‚¹ãƒ†ãƒƒãƒ—: é‡ã¿ã‚’æ›´æ–°
        optimizer.step()
        
        # ãƒ­ã‚°å‡ºåŠ›
        if step % 50 == 0:
            print(f" Â Epoch: {epoch+1}/{num_epochs}, Step: {step}, Total Loss: {losses.item():.4f}, Cls Loss: {loss_dict['classification'].item():.4f}")
    
    end_time = time.time()
    print(f"\n--- Epoch {epoch+1} å®Œäº†ã€‚ å¹³å‡æå¤±: {total_epoch_loss / len(train_loader):.4f}, å‡¦ç†æ™‚é–“: {(end_time - start_time):.2f}s ---\n")

print("å…¨å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä¿å­˜
torch.save(model.state_dict(), 'retinanet_custom_weights_final.pth')

# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import os # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ“ä½œ
import time # å­¦ç¿’æ™‚é–“ã®è¨ˆæ¸¬
import glob # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆå–å¾—ç”¨
import numpy as np # æ•°å€¤è¨ˆç®—
from tqdm import tqdm # é€²æ—è¡¨ç¤º

# Pytorché–¢é€£
import torch # pytorchã®åŸºæœ¬æ©Ÿèƒ½
import torch.optim as optim # æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ (SGD)
from torch.utils.data import Dataset # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å®šç¾©ã¨ä½¿ç”¨
from torch.utils.data import DataLoader # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å®šç¾©ã¨ä½¿ç”¨
from torchvision import transforms as T # ç”»åƒå¤‰æ›(Tensorã«)
from torchvision.ops import box_iou # IoUã®è¨ˆç®—(IoUï¼š)

# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ç”¨
from resnet18_backbone import resnet18 # ResNet18ã®ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³
from torchvision.models.detection.backbone_utils import _resnet_fpn_extractor # ResNetã‹ã‚‰FPNã‚’æ§‹ç¯‰
from torchvision.ops.feature_pyramid_network import LastLevelP6P7 # FPNã®æœ€çµ‚ãƒ¬ãƒ™ãƒ«(P6,P7)ã‚’è¿½åŠ ã™ã‚‹
from torchvision.models.detection.anchor_utils import AnchorGenerator # RetinaNetã®ã‚¢ãƒ³ã‚«ãƒ¼ç”Ÿæˆå™¨
from torchvision.models.detection import RetinaNet # RetinaNetãƒ¢ãƒ‡ãƒ«

# ãƒ‡ãƒ¼ã‚¿
from sklearn.model_selection import train_test_split # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ç”¨
from PIL import Image # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨RBGå¤‰æ›


# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ•´ãˆã‚‹ã‚¯ãƒ©ã‚¹
class CustomObjectDetectionDataset(Dataset): # DAtasetã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿
    # åˆæœŸåŒ–å‡¦ç†
    def __init__(self, img_list, root, transforms=None): 
        self.root = root # .ptsãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹rootã‚’ä¿æŒ
        self.transforms = transforms # ç”»åƒã«é©å¿œã™ã‚‹å‰å‡¦ç†(ä»Šå›ã¯ãªã—)
        self.imgs = img_list # ç”»åƒãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’ä¿æŒã™ã‚‹

    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹    
    def _parse_pts(self, pts_path):
        
        # åˆæœŸåŒ–
        boxes = [] # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
        labels = [] # ãƒ©ãƒ™ãƒ«

        # ãƒ‘ã‚¹ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ç©ºã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã¨ãƒ©ãƒ™ãƒ«ã‚’è¿”ã™
        if not os.path.exists(pts_path):
            return np.empty((0, 4), dtype=np.float32), np.empty((0,), dtype=np.int64)
        
        # .ptsãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        xs, ys = [], []
        with open(pts_path, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith("version") or line in ["{", "}"]: # ç©ºè¡Œã‚„ãƒ˜ãƒƒãƒ€ãƒ¼ã€æ³¢æ‹¬å¼§ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    continue

                parts = line.split()
                if len(parts) != 2: # åº§æ¨™ãŒäºŒã¤(x,y)ã®ã¿é€šã™
                    continue

                try:
                    x, y = float(parts[0]), float(parts[1])
                    xs.append(x)
                    ys.append(y) # åº§æ¨™ãŒäºŒã¤ã‚ã£ãŸã‚‰ãã‚Œãã‚Œä¿å­˜
                except ValueError:
                    continue

        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ä½œæˆ
        if len(xs) >= 2 and len(ys) >= 2:
            xmin, xmax = min(xs), max(xs)
            ymin, ymax = min(ys), max(ys)
            boxes = np.array([[xmin, ymin, xmax, ymax]], dtype=np.float32)
            labels = np.array([1], dtype=np.int64)  # å…¨ã¦1ã«ã—ã¦å˜ä¸€ã‚¯ãƒ©ã‚¹æ‰±ã„
        else:
            # ç‚¹ãŒè¶³ã‚Šãªã„å ´åˆã¯ç©ºã«ã—ã¦ãŠã
            boxes = np.empty((0, 4), dtype=np.float32)
            labels = np.empty((0,), dtype=np.int64)

        return boxes, labels

        
    def __getitem__(self, idx): # æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹(ç•ªå·)ã®ç”»åƒã¨ï½±ï¾‰ï¾ƒï½°ï½¼ï½®ï¾ã‚’è¿”ã™
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ§‹ç¯‰
        img_path_full = self.imgs[idx] # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
        img_filename = os.path.basename(img_path_full) # ç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¾—ã‚‹
        base_name = os.path.splitext(img_filename)[0] # ç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’é™¤ã„ãŸåå‰ã‚’å¾—ã‚‹
        pts_filename = base_name + ".pts" # .ptsãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½œæˆ
        pts_path = os.path.join(self.root, pts_filename) # .ptsãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ä½œæˆ

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        img = Image.open(img_path_full).convert("RGB") # ç”»åƒã‚’RGBå½¢å¼ã§èª­ã¿è¾¼ã‚€
        boxes_np, labels_np = self._parse_pts(pts_path) # .ptsãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã¨ãƒ©ãƒ™ãƒ«ã‚’Numpyé…åˆ—ã§å–å¾—

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¾æ›¸ã®ä½œæˆ
        if boxes_np.size == 0: # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ãŒç©ºãªã‚‰ç©ºã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
            boxes = torch.empty((0, 4), dtype=torch.float32)
            labels = torch.empty((0,), dtype=torch.int64)
        else: # NumPyé…åˆ—ã‚’Pytorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            boxes = torch.as_tensor(boxes_np, dtype=torch.float32)
            labels = torch.as_tensor(labels_np, dtype=torch.int64)
        
        target = {} # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¾æ›¸ã®æ§‹ç¯‰
        target["boxes"] = boxes 
        target["labels"] = labels
        target["image_id"] = torch.tensor([idx])
        
        # ç”»åƒå¤‰æ›ã®é©ç”¨
        if self.transforms is not None:
            img = self.transforms(img) # å‰å‡¦ç†ã‚’é©ç”¨

        return img, target
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã‚’è¿”ã™
    def __len__(self):
        return len(self.imgs)

# å‰å‡¦ç†(Transforms)ã®å®šç¾©
def get_transform(train):
    t = [T.ToTensor()] # PILç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«å½¢å¼ã«å¤‰æ›
    if train: # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
        # t.append(T.RandomHorizontalFlip(0.5)) # 50%ã®ç¢ºç‡ã§å·¦å³åè»¢
        pass 
    return T.ToTensor()

# ã‚³ãƒ¬ãƒ¼ãƒˆé–¢æ•°(Collate Function)ã®å®šç¾© (RetinaNetã«ã¯ãƒªã‚¹ãƒˆå½¢å¼ã§æ¸¡ã™ãŸã‚)
def custom_collate_fn(batch): # batchï¼š(img,target)
    images = [item[0] for item in batch] # ç”»åƒã®ã¿ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    targets = [item[1] for item in batch] # ï½±ï¾‰ï¾ƒï½°ï½¼ï½®ï¾ã®ã¿ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    return images, targets


# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åˆ†å‰²
DATA_ROOT = '/workspace/dataset' # ãƒ‡ãƒ¼ã‚¿ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š

# å…¨ã¦ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
all_imgs = sorted(glob.glob(os.path.join(DATA_ROOT, "*.jpg"))) # shorted()ã§ãƒ•ã‚¡ã‚¤ãƒ«åé †ã«ä¸¦ã³æ›¿ãˆã‚‰ã‚Œã‚‹
print(f"å…¨ç”»åƒæ•°: {len(all_imgs)}")

# å­¦ç¿’ç”¨ (80%) ã¨ãƒ†ã‚¹ãƒˆç”¨ (20%) ã«åˆ†å‰²
train_imgs, test_imgs = train_test_split( 
    all_imgs, 
    test_size=0.2, 
    random_state=42 # ã‚·ãƒ¼ãƒ‰å›ºå®šã§å†ç¾æ€§ã‚’ç¢ºä¿
)
print(f"å­¦ç¿’ç”¨ã‚µãƒ³ãƒ—ãƒ«æ•° (80%): {len(train_imgs)}, ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«æ•° (20%): {len(test_imgs)}")

# Datasetã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆã€€ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
train_dataset = CustomObjectDetectionDataset(train_imgs, DATA_ROOT, get_transform(train=True)) # æ‹¡å¼µå¯èƒ½
test_dataset = CustomObjectDetectionDataset(test_imgs, DATA_ROOT, get_transform(train=False))

# DataLoaderã®ä½œæˆ
train_loader = DataLoader(
    train_dataset,
    batch_size=16, 
    shuffle=True, # ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã‚ã‚Š
    num_workers=2, # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã®ä¸¦åˆ—å‡¦ç†
    collate_fn=custom_collate_fn # ç”»åƒã¨ï½±ï¾‰ï¾ƒï½°ï½¼ï½®ï¾ã‚’ãã‚Œãã‚Œãƒªã‚¹ãƒˆå½¢å¼ã§ã¾ã¨ã‚ã‚‹
)

# TestLoaderã®ä½œæˆ
test_loader = DataLoader(
    test_dataset,
    batch_size=2, 
    shuffle=False, # ã‚·ãƒ£ãƒƒãƒ•ãƒ«ãªã—
    num_workers=2, 
    collate_fn=custom_collate_fn 
)


# ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã‚¢ãƒ³ã‚«ãƒ¼ç”Ÿæˆå™¨ã®æ§‹ç¯‰
custom_backbone = resnet18(pretrained=False) # ResNet18ã‚’ä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹ (é‡ã¿ãªã—)

# FPNã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®è¨­å®š
out_channels = 256 # FPNã®å„å‡ºåŠ›ãƒãƒƒãƒ—ã®ãƒãƒ£ãƒ³ãƒãƒ«æ•°

backbone_fpn = _resnet_fpn_extractor(
    custom_backbone, 
    trainable_layers=5, # ResNetã®ã™ã¹ã¦ã®å±¤ã‚’å­¦ç¿’å¯èƒ½ã«
    extra_blocks=LastLevelP6P7(out_channels, out_channels) # ã•ã‚‰ã«é«˜ãƒ¬ãƒ™ãƒ«ã®ç‰¹å¾´ãƒãƒƒãƒ—(P6,P7)ã‚’è¿½åŠ 
)

# ã‚¢ãƒ³ã‚«ãƒ¼ç”Ÿæˆå™¨ã®å®šç¾© (å€™è£œé ˜åŸŸã®ä½œæˆ)
anchor_generator = AnchorGenerator(
    sizes=((32,), (64,), (128,), (256,), (512,), (1024,)), # ã‚¢ãƒ³ã‚«ãƒ¼ã®ã‚µã‚¤ã‚º
    aspect_ratios=((0.5, 1.0, 2.0),) * 6 # ç¸¦æ¨ªæ¯”
)


# RetinaNetãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
NUM_CLASSES = 1 # æ¤œå‡ºå¯¾è±¡(èƒŒæ™¯ã‚’é™¤ã)

model = RetinaNet(
    backbone=backbone_fpn,
    num_classes=NUM_CLASSES,
    anchor_generator=anchor_generator
)

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®å®šç¾© (SGDï¼šç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•)
optimizer = optim.SGD(
    model.parameters(), 
    lr=0.0001, # å­¦ç¿’ç‡
    momentum=0.9,
    weight_decay=0.0001 # éå­¦ç¿’é˜²æ­¢
)

# å­¦ç¿’ã™ã‚‹ã‚¨ãƒãƒƒã‚¯æ•°
num_epochs = 30 

# ç‰©ä½“æ¤œå‡ºç²¾åº¦ã‚’IoUã§è©•ä¾¡ã™ã‚‹
def evaluate_iou(model, dataloader, device):
    model.eval() # è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰
    total_iou = 0.0
    total_images = 0

    with torch.no_grad():
        for images, targets in tqdm(dataloader, desc="Evaluating IoU"):
            images = [img.to(device) for img in images]
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            outputs = model(images) # ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬

            for output, target in zip(outputs, targets):
                pred_boxes = output['boxes']
                true_boxes = target['boxes']

                if pred_boxes.size(0) == 0 or true_boxes.size(0) == 0:
                    continue  # ç©ºãªã‚‰ã‚¹ã‚­ãƒƒãƒ—

                # IoUã®è¨ˆç®—
                ious = box_iou(pred_boxes, true_boxes)  # [N_pred, N_true] ã®IoUè¡Œåˆ—
                max_ious, _ = ious.max(dim=1)  # å„äºˆæ¸¬ã«å¯¾ã—ã¦æœ€å¤§IoUã‚’å–å¾—

                total_iou += max_ious.mean().item()
                total_images += 1

    if total_images == 0:
        print("âš ï¸ IoUè©•ä¾¡ã§ãã‚‹ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else: # å¹³å‡IoUã®å‡ºåŠ›
        avg_iou = total_iou / total_images
        print(f"\nğŸ“Š å¹³å‡IoU: {avg_iou:.4f}ï¼ˆ{total_images}æšã®ç”»åƒã§è©•ä¾¡ï¼‰\n")

# ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã‚‹
model.train() # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰

for epoch in range(1, num_epochs + 1):
    start_time = time.time()
    total_epoch_loss = 0
    
    for step, (images, targets) in enumerate(tqdm(train_loader, desc=f"Epoch [{epoch}/{num_epochs}]")):
        # ãƒ‡ãƒ¼ã‚¿ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’GPUã«ç§»å‹•
        images = [image.to(device).to(torch.float32) for image in images]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        # å‹¾é…ã‚’åˆæœŸåŒ–
        optimizer.zero_grad()

        # æå¤±è¨ˆç®—
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        total_epoch_loss += losses.item()

        # NaNãƒã‚§ãƒƒã‚¯
        if torch.isnan(losses):
            print(f"NaN detected at step {step}, skipping this batch.")
            continue

        # ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹: å‹¾é…ã‚’è¨ˆç®—
        losses.backward()

        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®ã‚¹ãƒ†ãƒƒãƒ—: é‡ã¿ã‚’æ›´æ–°
        optimizer.step() 
        
    end_time = time.time()
    tqdm.write(f"--- Epoch [{epoch}/{num_epochs}] å®Œäº†ã€‚ å¹³å‡æå¤±: {total_epoch_loss / len(train_loader):.4f}, å‡¦ç†æ™‚é–“: {(end_time - start_time):.2f}s ---")

print("å…¨å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä¿å­˜
torch.save(model.state_dict(), 'retinanet_custom_weights_final.pth')

# å­¦ç¿’å¾Œã«IoUã‚’è©•ä¾¡
evaluate_iou(model, test_loader, device)
